# NL2SQL Agent with AG2 Multi-Agent System# NL2SQL Agent with AgentOps Self-Hosting



Natural Language to SQL conversion system with autonomous multi-agent collaboration powered by AG2 (AutoGen).Natural Language to SQL conversion system with full AgentOps observability platform (self-hosted).



## Features## Features



- ðŸ¤– **Multi-Agent Collaboration**: Three specialized AI agents working together- ðŸ—£ï¸ **Natural Language Interface**: Query databases using Japanese or English

  - **SQL Specialist**: Database schema analysis and SQL query generation- ðŸš€ **High Performance**: DuckDB for sub-100ms query execution

  - **Web Researcher**: Real-time web search and information gathering- ï¿½ **AgentOps Self-Hosted**: Full observability stack with traces, metrics, and analytics

  - **Data Analyst**: Statistical analysis and predictions with code execution- ðŸ’¬ **Chat Interface**: Streamlit for intuitive user experience

- ðŸ—£ï¸ **Natural Language Interface**: Query databases using Japanese natural language- ðŸ‡¯ðŸ‡µ **Japanese Support**: Optimized for Japanese e-commerce data

- ðŸš€ **High Performance**: DuckDB for sub-100ms query execution- ï¿½ **Distributed Tracing**: OpenTelemetry integration for end-to-end visibility

- ðŸ“Š **Full Observability**: OpenTelemetry + ClickHouse for distributed tracing

- ðŸ’¬ **Interactive UI**: Streamlit for intuitive multi-agent conversation## Architecture

- ðŸ‡¯ðŸ‡µ **Japanese Optimized**: LLM fine-tuned for Japanese e-commerce queries

```

## Architectureâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚                        User Browser                          â”‚

```â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                                â”‚

â”‚                        User Browser                          â”‚           â”‚ Port 8501                      â”‚ Port 3000

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â–¼                                â–¼

                           â”‚ Port 8501â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

                           â–¼â”‚   Streamlit UI      â”‚          â”‚ AgentOps Dashboard  â”‚

                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  (Chat Interface)   â”‚          â”‚   (Next.js)         â”‚

                â”‚   Streamlit UI      â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                â”‚  (Chat Interface)   â”‚           â”‚                                â”‚

                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ @agent, @operation             â”‚ API Calls

                           â”‚           â–¼                                â–¼

                           â–¼â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚   NL2SQL Agent      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  AgentOps API       â”‚

                â”‚  MultiAgentOrchestrator        â”‚â”‚  (with decorators)  â”‚ Track    â”‚   (FastAPI)         â”‚

                â”‚  (AG2 GroupChat Manager)       â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                                â”‚

                           â”‚           â”‚ SQL Queries                    â”‚ Store metadata

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â–¼                                â–¼

        â”‚                  â”‚                  â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

        â–¼                  â–¼                  â–¼â”‚     DuckDB          â”‚          â”‚   PostgreSQL        â”‚

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  (E-commerce Data)  â”‚          â”‚  (User/API Data)    â”‚

â”‚ SQL Agent    â”‚  â”‚ Web Agent    â”‚  â”‚ Reasoning    â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”‚              â”‚  â”‚              â”‚  â”‚ Agent        â”‚           â”‚

â”‚ â€¢ Schema     â”‚  â”‚ â€¢ DuckDuckGo â”‚  â”‚ â€¢ Python     â”‚           â”‚ Traces via OTLP

â”‚   Analysis   â”‚  â”‚   Search     â”‚  â”‚   Execution  â”‚           â–¼

â”‚ â€¢ SQL Gen    â”‚  â”‚ â€¢ Web Scrape â”‚  â”‚ â€¢ Statistics â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  OTel Collector     â”‚

       â”‚                 â”‚                 â”‚â”‚  (Port 4318)        â”‚

       â”‚ MCP Tools       â”‚ MCP Tools       â”‚ MCP Toolsâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

       â–¼                 â–¼                 â–¼           â”‚

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚ Store traces

â”‚ DB Tools     â”‚  â”‚ Web Tools    â”‚  â”‚ Interpreter  â”‚           â–¼

â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

       â”‚â”‚    ClickHouse       â”‚

       â”‚ SQL Queriesâ”‚  (Traces & Metrics) â”‚

       â–¼â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”```

â”‚     DuckDB          â”‚

â”‚  (E-commerce Data)  â”‚## Quick Start

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

       â”‚### Prerequisites

       â”‚ Traces via OTLP (Port 4318)

       â–¼- Docker and Docker Compose

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”- At least 4GB RAM available

â”‚  OTel Collector     â”‚

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜### 1. Clone Repository

           â”‚

           â–¼```bash

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”git clone https://github.com/michiroooo/nl2sql-agent.git

â”‚    ClickHouse       â”‚cd nl2sql-agent

â”‚  (Traces & Metrics) â”‚```

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```### 2. Setup Environment



## System Components```bash

cp .env.example .env

### 1. MultiAgentOrchestrator (`ag2_orchestrator.py`)# Edit .env and set a secure JWT_SECRET_KEY

```

**Role**: Coordinates multi-agent collaboration using AG2's GroupChat pattern.

**Required environment variables:**

**Key Classes**:- `JWT_SECRET_KEY`: Set a random 32+ character string for JWT signing

- `AgentConfig`: LLM configuration for Ollama endpoint- `CLICKHOUSE_PASSWORD`: Password for ClickHouse (default: `password`)

- `MultiAgentOrchestrator`: Main orchestration class managing agent interactions- `POSTGRES_PASSWORD`: Password for PostgreSQL (default: `postgres`)



**Communication Flow**:### 3. Generate Sample Database

1. User query received from Streamlit

2. Orchestrator creates GroupChat with all agents```bash

3. GroupChatManager automatically selects appropriate agentcd data

4. Agents collaborate through message passingpip install -r requirements.txt

5. Final result returned to userpython setup_database.py

cd ..

**Key Methods**:```

```python

execute(query: str) -> dict[str, Any]### 4. Start All Services

```

- Executes query using multi-agent collaboration```bash

- Returns conversation history and participating agentsdocker compose up -d

```

### 2. Specialized Agents

This will start:

#### SQL Agent (`create_sql_agent()`)- **Streamlit UI** (Port 8501) - Chat interface

- **Purpose**: Database specialist for schema analysis and SQL generation- **AgentOps Dashboard** (Port 3000) - Observability dashboard

- **Tools**: `get_database_schema()`, `execute_sql_query()`- **AgentOps API** (Port 8000) - Backend API

- **Behavior**: Analyzes user intent, generates SQL, executes queries- **Ollama** (Port 11434) - LLM inference

- **ClickHouse** (Port 8123, 9000) - Trace storage

#### Web Agent (`create_web_agent()`)- **PostgreSQL** (Port 5432) - Metadata storage

- **Purpose**: Web research specialist for external information- **OTel Collector** (Port 4317, 4318) - Trace collection

- **Tools**: `web_search()`, `scrape_webpage()`

- **Behavior**: Searches web, scrapes content, summarizes findings### 5. Download Ollama Model



#### Reasoning Agent (`create_reasoning_agent()`)```bash

- **Purpose**: Data analyst with code execution capabilitiesdocker exec -it nl2sql-ollama ollama pull qwen2.5-coder:7b-instruct-q4_K_M

- **Tools**: `python_interpreter()`, LocalCommandLineCodeExecutor```

- **Behavior**: Statistical analysis, predictions, data visualization

### 6. Access Interfaces

### 3. MCP Tools (`mcp_tools/`)

- **Streamlit UI**: http://localhost:8501

**Model Context Protocol (MCP)** provides standardized tool interfaces for agents.- **AgentOps Dashboard**: http://localhost:3000

- **AgentOps API Docs**: http://localhost:8000/docs

#### Database Tools (`database.py`)

```python## Usage

create_database_tools() -> dict[str, Callable]

```### Example Queries

- `get_database_schema(query)`: Returns table schemas with row counts

- `execute_sql_query(sql)`: Executes SQL with 50-row limit**Japanese:**

```

#### Web Tools (`web.py`)é¡§å®¢æ•°ã‚’æ•™ãˆã¦

```python2024å¹´ã§æœ€ã‚‚å£²ã‚ŒãŸå•†å“ã®åå‰ã¨å£²ä¸Šå€‹æ•°ã‚’æ•™ãˆã¦

create_web_tools() -> dict[str, Callable]æ±äº¬éƒ½åœ¨ä½ã®é¡§å®¢æ•°ã‚’æ•™ãˆã¦

```è³¼å…¥é‡‘é¡ãƒˆãƒƒãƒ—3ã®é¡§å®¢åã¨è³¼å…¥é‡‘é¡ã‚’æ•™ãˆã¦

- `web_search(query)`: DuckDuckGo API search (top 5 results)```

- `scrape_webpage(url)`: HTML content extraction (2000 char limit)

**English:**

#### Interpreter Tool (`interpreter.py`)```

```pythonShow me the number of customers

create_interpreter_tool() -> dict[str, Callable]What product sold the most in 2024?

```How many customers are from Tokyo?

- `python_interpreter(code)`: Safe Python execution with whitelistShow top 3 customers by purchase amount

  - Allowed: math, statistics, datetime, json, re```

  - Blocked: File I/O, network, system calls

See `data/sample_queries.md` for more examples.

### 4. Streamlit UI (`ui/app.py`)

### Viewing Traces in AgentOps Dashboard

**Role**: Interactive chat interface with agent conversation visualization.

1. Open http://localhost:3000

**Features**:2. Navigate to **Traces** section

- Query input with sample buttons3. View detailed execution traces with:

- Agent conversation history display   - Operation timeline

- Real-time agent message streaming   - SQL query generation steps

- Participating agents summary   - Database execution times

   - LLM prompts and responses

**Key Components**:   - Error traces

```python

MultiAgentOrchestrator(## Development

    model="qwen2.5-coder:7b-instruct-q4_K_M",

    base_url="http://ollama:11434"### Project Structure

)

``````

.

## Module Communicationâ”œâ”€â”€ docker-compose.yml

â”œâ”€â”€ agentops/

### 1. User â†’ UI â†’ Orchestratorâ”‚   â”œâ”€â”€ otel-collector-config.yaml  # OTel configuration

```â”‚   â””â”€â”€ clickhouse/

User Input (Streamlit)â”‚       â””â”€â”€ migrations/

    â†’ st.text_area(query)â”‚           â””â”€â”€ 0000_init.sql       # ClickHouse schema

    â†’ orchestrator.execute(query)â”œâ”€â”€ ui/

    â†’ GroupChat initializationâ”‚   â”œâ”€â”€ app.py            # Streamlit UI

```â”‚   â”œâ”€â”€ Dockerfile

â”‚   â””â”€â”€ requirements.txt

### 2. Orchestrator â†’ Agentsâ”œâ”€â”€ function/

```â”‚   â”œâ”€â”€ agent.py          # NL2SQL agent (with @agent, @operation)

GroupChatManagerâ”‚   â”œâ”€â”€ database.py       # DuckDB manager

    â†’ speaker_selection_method="auto"â”‚   â””â”€â”€ requirements.txt

    â†’ Select appropriate agent based on contextâ”œâ”€â”€ data/

    â†’ Agent.receive(message)â”‚   â”œâ”€â”€ setup_database.py # Sample data generator

```â”‚   â””â”€â”€ ecommerce.db      # DuckDB database

â””â”€â”€ docs/

### 3. Agent â†’ MCP Tools    â””â”€â”€ design.md         # Design document

``````

Agent.register_function(tool)

    â†’ Tool invocation via function_map### Local Development

    â†’ Tool execution in safe sandbox

    â†’ Result returned to agent```bash

```# Install dependencies

cd function

### 4. Agent â†’ Databasepip install -r requirements.txt

```

SQL Agent# Start FastAPI server

    â†’ execute_sql_query(sql)uvicorn main:app --reload --port 8001

    â†’ DuckDB connection (DATABASE_PATH)```

    â†’ Query execution + formatting

    â†’ Result (max 50 rows)### Database Schema

```

```sql

### 5. Telemetry â†’ ClickHouse-- Customers

```customer_id, customer_name, prefecture, registration_date

All Operations

    â†’ OpenTelemetry instrumentation-- Products

    â†’ OTLP export (HTTP 4318)product_id, product_name, category, price, stock_quantity

    â†’ OTel Collector processing

    â†’ ClickHouse storage (otel_2.otel_traces)-- Orders

```order_id, customer_name, product_id, quantity, order_date, total_amount

```

## Quick Start

## Configuration

### Prerequisites

### Environment Variables

- Docker and Docker Compose

- At least 8GB RAM (for Ollama + agents)| Variable | Description | Default |

- 10GB disk space (for models)|----------|-------------|---------|

| `AGENTOPS_API_KEY` | AgentOps API key (optional for self-hosted) | - |

### 1. Clone Repository| `AGENTOPS_API_ENDPOINT` | AgentOps API endpoint | `http://localhost:8000` |

| `AGENTOPS_EXPORTER_ENDPOINT` | OTLP exporter endpoint | `http://localhost:4318/v1/traces` |

```bash| `DATABASE_PATH` | Path to DuckDB file | `/app/data/ecommerce.db` |

git clone https://github.com/michiroooo/nl2sql-agent.git| `OLLAMA_BASE_URL` | Ollama API endpoint | `http://ollama:11434` |

cd nl2sql-agent| `OLLAMA_MODEL` | LLM model name | `qwen2.5-coder:7b-instruct-q4_K_M` |

```| `JWT_SECRET_KEY` | JWT signing secret (32+ chars) | **Required** |

| `CLICKHOUSE_PASSWORD` | ClickHouse password | `password` |

### 2. Setup Environment| `POSTGRES_PASSWORD` | PostgreSQL password | `postgres` |



```bash### AgentOps Decorators

cp .env.example .env

# Edit .env if needed (default values work)The agent uses AgentOps decorators for automatic tracing:

```

```python

**Key environment variables**:from agentops.sdk.decorators import agent, operation

- `DATABASE_PATH=/app/data/ecommerce.db` - DuckDB location

- `OLLAMA_MODEL=qwen2.5-coder:7b-instruct-q4_K_M` - LLM model@agent

- `OLLAMA_BASE_URL=http://ollama:11434` - Ollama endpointclass NL2SQLAgent:

    @operation

### 3. Generate Sample Database    def _generate_sql(self, question: str) -> str:

        # Automatically tracked

```bash        pass

cd data    

pip install -r requirements.txt    @operation

python setup_database.py    def process_query(self, user_input: str) -> dict:

cd ..        # Automatically tracked

```        pass

```

This creates:

- **customers** table: 200 Japanese e-commerce customers## Monitoring & Observability

- **orders** table: 500 orders with products

- **products** table: 20 Japanese products### Metrics Available



### 4. Start AG2 Multi-Agent System- **Query Performance**: End-to-end latency, SQL generation time, DB execution time

- **Success Rates**: Query success/failure rates, error types

```bash- **LLM Usage**: Token counts, model performance, prompt effectiveness

docker compose -f docker-compose-ag2.yml up -d- **System Health**: Database connection status, service availability

```

### Trace Details

This starts:

- **ClickHouse** (Ports 8123, 9000) - Trace storageEach query generates a trace with:

- **OTel Collector** (Ports 4317, 4318, 8888) - Telemetry pipeline1. **Agent Span**: Overall query processing

- **Ollama** (Port 11434) - LLM inference2. **SQL Generation Operation**: LLM prompt and generated SQL

- **Streamlit UI** (Port 8501) - Multi-agent interface3. **Database Execution**: Query execution time and results

4. **Formatting**: Result formatting duration

### 5. Download LLM Model

## Troubleshooting

```bash

docker exec nl2sql-ollama ollama pull qwen2.5-coder:7b-instruct-q4_K_M### Services Not Starting

```

```bash

This downloads ~4.7GB model optimized for:# Check all container status

- Japanese language understandingdocker compose ps

- Code generation (SQL, Python)

- Instruction following# View logs for specific service

docker compose logs -f streamlit-ui

### 6. Access Systemdocker compose logs -f agentops-api

docker compose logs -f clickhouse

- **Streamlit UI**: http://localhost:8501```

- **ClickHouse**: http://localhost:8123 (user: default, password: password)

- **OTel Collector Health**: http://localhost:8888/metrics### ClickHouse Connection Error



## Usage Examples```bash

# Verify ClickHouse is healthy

### Example 1: Database Querydocker exec -it nl2sql-clickhouse clickhouse-client --query "SELECT 1"

```

User: "2024å¹´ã§æœ€ã‚‚å£²ã‚ŒãŸå•†å“ã¯ï¼Ÿ"# Check schema creation

docker exec -it nl2sql-clickhouse clickhouse-client --query "SHOW DATABASES"

Agent Flow:```

1. SQL Agent: Analyzes schema â†’ Generates SQL

2. SQL Agent: Executes query â†’ Returns top product### AgentOps Dashboard Not Loading

3. Result: "å•†å“å: ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³, å£²ä¸Šå€‹æ•°: 45å€‹"

``````bash

# Check API connectivity

### Example 2: Web Research + Analysiscurl http://localhost:8000/health

```

User: "æœ€æ–°ã®Eã‚³ãƒžãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’èª¿æŸ»ã—ã¦ã€å½“ç¤¾ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦"# Check dashboard logs

docker compose logs -f agentops-dashboard

Agent Flow:```

1. Web Agent: DuckDuckGo search â†’ Scrapes articles

2. SQL Agent: Fetches sales data from database### Ollama Connection Error

3. Reasoning Agent: Statistical comparison â†’ Insights

4. Result: Multi-agent collaborative analysis```bash

```# Check Ollama is running

docker logs nl2sql-ollama

### Example 3: Predictive Analysis

```# Verify model is downloaded

User: "æ˜Žæ—¥ã®å£²ä¸Šã‚’äºˆæ¸¬ã—ã¦"docker exec -it nl2sql-ollama ollama list

```

Agent Flow:

1. SQL Agent: Historical sales data retrieval### Database Not Found

2. Reasoning Agent: Python time-series analysis

3. Reasoning Agent: Prediction with confidence interval```bash

4. Result: "äºˆæ¸¬å£²ä¸Š: Â¥1,234,567 Â± Â¥50,000"# Regenerate database

```cd data

python setup_database.py

## Sample Queries```



### Database Queries (SQL Agent)## Performance Tips

- "é¡§å®¢æ•°ã‚’æ•™ãˆã¦"

- "2024å¹´ã§æœ€ã‚‚å£²ã‚ŒãŸå•†å“ã®åå‰ã¨å£²ä¸Šå€‹æ•°ã‚’æ•™ãˆã¦"1. **ClickHouse**: Traces are kept for 3 days (TTL). Adjust in migration SQL if needed.

- "æ±äº¬éƒ½ã®é¡§å®¢ã®å¹³å‡è³¼å…¥é‡‘é¡ã¯ï¼Ÿ"2. **Memory**: Allocate at least 4GB RAM for all services.

3. **Model Selection**: Use quantized models (q4_K_M) for faster inference.

### Web Research (Web Agent)

- "æœ€æ–°ã®Eã‚³ãƒžãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’èª¿æŸ»ã—ã¦"## Contributing

- "DuckDBã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ä½¿ã„æ–¹ã‚’æ•™ãˆã¦"

1. Fork the repository

### Data Analysis (Multi-Agent)2. Create a feature branch (`git checkout -b feature/amazing-feature`)

- "ä»Šæ—¥ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ˜Žæ—¥ã®å£²ä¸Šã‚’äºˆæ¸¬ã—ã¦"3. Commit your changes (`git commit -m 'Add amazing feature'`)

- "é¡§å®¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æžã‚’å®Ÿæ–½ã—ã¦æ”¹å–„ææ¡ˆã‚’ã—ã¦"4. Push to the branch (`git push origin feature/amazing-feature`)

5. Open a Pull Request

## Configuration

## License

### Ollama Models

MIT License

Default: `qwen2.5-coder:7b-instruct-q4_K_M` (4.7GB)

## Links

Alternative models:

```bash- [AgentOps GitHub](https://github.com/AgentOps-AI/agentops)

# Smaller model (1.7GB, faster but less capable)- [AgentOps Docs](https://docs.agentops.ai)

docker exec nl2sql-ollama ollama pull gemma2:2b-instruct-q4_K_M- [DuckDB](https://duckdb.org)

- [Ollama](https://ollama.ai)

# Update docker-compose-ag2.yml:- [ClickHouse](https://clickhouse.com)

environment:- [OpenTelemetry](https://opentelemetry.io)

  OLLAMA_MODEL: gemma2:2b-instruct-q4_K_M

```

### Agent Behavior

Edit `function/ag2_orchestrator.py`:

**Max conversation rounds**:
```python
self.group_chat = GroupChat(
    agents=[...],
    max_round=10  # Increase for complex queries
)
```

**Temperature (creativity)**:
```python
AgentConfig(temperature=0.0)  # 0.0=deterministic, 1.0=creative
```

### Tool Security

Edit `function/mcp_tools/interpreter.py`:

**Allowed imports**:
```python
ALLOWED_IMPORTS = {'math', 'statistics', 'datetime', 'json', 're'}
```

## Observability

### ClickHouse Queries

**View traces**:
```sql
SELECT 
    Timestamp, 
    ServiceName, 
    SpanName, 
    Duration
FROM otel_2.otel_traces
ORDER BY Timestamp DESC
LIMIT 100;
```

**Agent performance**:
```sql
SELECT 
    SpanAttributes['agent.name'] as agent,
    AVG(Duration) as avg_duration_ns,
    COUNT(*) as invocations
FROM otel_2.otel_traces
WHERE SpanName LIKE '%agent%'
GROUP BY agent;
```

### OTel Collector Metrics

```bash
curl http://localhost:8888/metrics
```

## Development

### Project Structure

```
nl2sql-agent/
â”œâ”€â”€ function/
â”‚   â”œâ”€â”€ ag2_orchestrator.py      # Multi-agent orchestration
â”‚   â”œâ”€â”€ database.py               # DuckDB connection
â”‚   â”œâ”€â”€ main.py                   # FastAPI entry (legacy)
â”‚   â”œâ”€â”€ mcp_tools/
â”‚   â”‚   â”œâ”€â”€ database.py           # DB tools
â”‚   â”‚   â”œâ”€â”€ web.py                # Web tools
â”‚   â”‚   â””â”€â”€ interpreter.py        # Code execution
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py                    # Streamlit interface
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ setup_database.py         # Sample data generation
â”‚   â””â”€â”€ sample_queries.md
â”œâ”€â”€ agentops/
â”‚   â”œâ”€â”€ otel-collector-config.yaml
â”‚   â””â”€â”€ clickhouse/
â”‚       â””â”€â”€ migrations/
â”‚           â””â”€â”€ 0000_init.sql
â”œâ”€â”€ docker-compose-ag2.yml        # AG2 deployment
â””â”€â”€ README.md
```

### Adding New Tools

1. Create tool in `function/mcp_tools/`:
```python
def create_new_tool() -> dict[str, Callable]:
    def tool_function(param: str) -> str:
        # Implementation
        return result
    
    return {"tool_name": tool_function}
```

2. Register in agent:
```python
tools = create_new_tool()
agent.register_function(function_map=tools)
```

### Adding New Agent

1. Define in `ag2_orchestrator.py`:
```python
def create_new_agent(config: AgentConfig) -> AssistantAgent:
    return AssistantAgent(
        name="specialist_name",
        system_message="Role description...",
        llm_config=config.llm_config
    )
```

2. Add to orchestrator:
```python
self.new_agent = create_new_agent(config)
self.group_chat = GroupChat(
    agents=[..., self.new_agent],
    ...
)
```

## Troubleshooting

### Issue: Agents not responding

**Check Ollama**:
```bash
docker logs nl2sql-ollama --tail 50
docker exec nl2sql-ollama ollama list
```

**Solution**: Ensure model is downloaded
```bash
docker exec nl2sql-ollama ollama pull qwen2.5-coder:7b-instruct-q4_K_M
```

### Issue: Import errors

**Check pyautogen version**:
```bash
docker exec nl2sql-streamlit pip show pyautogen
```

**Expected**: `Version: 0.2.35` (not 0.10.0)

**Solution**: Rebuild with correct version
```bash
docker compose -f docker-compose-ag2.yml build --no-cache streamlit-ui
```

### Issue: Database connection failed

**Check DuckDB**:
```bash
docker exec nl2sql-streamlit ls -la /app/data/
```

**Solution**: Generate database
```bash
cd data
python setup_database.py
```

### Issue: Traces not appearing in ClickHouse

**Check OTel Collector**:
```bash
docker logs nl2sql-otel-collector --tail 50
```

**Expected**: "Everything is ready. Begin running and processing data."

**Check ClickHouse**:
```bash
docker exec nl2sql-clickhouse clickhouse-client --password password --query "SELECT COUNT(*) FROM otel_2.otel_traces"
```

## Performance

### Benchmarks (Apple M4 Max, 128GB RAM)

| Query Type | Agent Selection | Execution Time | Token Usage |
|------------|----------------|----------------|-------------|
| Simple SQL | SQL Agent | 2-5s | ~500 tokens |
| Web Search | Web Agent | 5-10s | ~800 tokens |
| Analysis | Multi-Agent | 15-30s | ~2000 tokens |

### Optimization Tips

1. **Reduce max_round**: Lower for simple queries
2. **Use smaller model**: gemma2:2b for faster responses
3. **Limit tool results**: Reduce row limits in tools
4. **Enable caching**: LLM response caching in Ollama

## License

MIT License - See LICENSE file for details

## Contributing

1. Fork repository
2. Create feature branch: `git checkout -b feature/new-feature`
3. Commit changes: `git commit -am 'Add new feature'`
4. Push to branch: `git push origin feature/new-feature`
5. Submit pull request

## References

- [AG2 (AutoGen) Documentation](https://microsoft.github.io/autogen/)
- [DuckDB Documentation](https://duckdb.org/docs/)
- [OpenTelemetry Python](https://opentelemetry.io/docs/languages/python/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Ollama Models](https://ollama.com/library)

## Support

For issues and questions:
- GitHub Issues: https://github.com/michiroooo/nl2sql-agent/issues
- Documentation: See `/docs` directory

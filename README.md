# NL2SQL Agent with AG2 Multi-Agent System

Natural Language to SQL conversion system with autonomous multi-agent collaboration powered by AG2 (AutoGen).

## Features

- ğŸ¤– **Multi-Agent Collaboration**: Three specialized AI agents working together
  - **SQL Specialist**: Database schema analysis and SQL query generation
  - **Web Researcher**: Real-time web search and information gathering
  - **Data Analyst**: Statistical analysis and predictions with code execution
- ğŸ—£ï¸ **Natural Language Interface**: Query databases using Japanese natural language
- ğŸš€ **High Performance**: DuckDB for sub-100ms query execution
- ğŸ“Š **Full Observability**: Phoenix (Arize AI) for automatic LLM tracing
- ğŸ’¬ **Interactive UI**: Streamlit for intuitive multi-agent conversation
- ğŸ‡¯ğŸ‡µ **Japanese Optimized**: LLM fine-tuned for Japanese e-commerce queries

## Quick Start

```bash
# Clone and setup
git clone https://github.com/michiroooo/nl2sql-agent.git
cd nl2sql-agent

# Generate sample database
cd data && pip install -r requirements.txt && python setup_database.py && cd ..

# Start system
docker compose -f docker-compose-ag2.yml up -d

# Download model
docker exec nl2sql-ollama ollama pull qwen2.5-coder:7b-instruct-q4_K_M

# Access UI at http://localhost:8501
```

## Architecture

```text
User Browser â†’ Streamlit UI â†’ MultiAgentOrchestrator â†’ [SQL, Web, Reasoning] Agents
                                                      â†“
                                                  MCP Tools
                                                      â†“
                                         [DuckDB, Web, Interpreter]
```

**è©³ç´°**: [docs/architecture.md](docs/architecture.md)

## Usage Examples

### Database Query
```
User: "2024å¹´ã§æœ€ã‚‚å£²ã‚ŒãŸå•†å“ã¯ï¼Ÿ"
â†’ SQL Agent analyzes schema â†’ Generates SQL â†’ Returns result
```

### Web Research
```
User: "æœ€æ–°ã®Eã‚³ãƒãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’èª¿æŸ»ã—ã¦"
â†’ Web Agent searches DuckDuckGo â†’ Scrapes content â†’ Summarizes
```

### Data Analysis
```
User: "æ˜æ—¥ã®å£²ä¸Šã‚’äºˆæ¸¬ã—ã¦"
â†’ SQL Agent gets historical data â†’ Reasoning Agent runs analysis â†’ Prediction
```

## Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_MODEL` | `qwen2.5-coder:7b-instruct-q4_K_M` | LLM model |
| `OLLAMA_BASE_URL` | `http://ollama:11434` | Ollama endpoint |
| `DATABASE_PATH` | `/app/data/ecommerce.db` | DuckDB path |
| `PHOENIX_COLLECTOR_ENDPOINT` | `http://localhost:6006` | Phoenix collector URL |

### Agent Settings

Edit `function/ag2_orchestrator.py`:

```python
# Max conversation rounds
max_round=10  # Increase for complex queries

# LLM temperature
temperature=0.0  # 0.0=deterministic, 1.0=creative
```

## Troubleshooting

### Agents Not Responding

Check Ollama:
```bash
docker logs nl2sql-ollama --tail 50
docker exec nl2sql-ollama ollama list
```

Ensure model is downloaded:
```bash
docker exec nl2sql-ollama ollama pull qwen2.5-coder:7b-instruct-q4_K_M
```

### Import Errors

Check pyautogen version:
```bash
docker exec nl2sql-streamlit pip show pyautogen
# Expected: Version: 0.2.35 (not 0.10.0)
```

Rebuild if needed:
```bash
docker compose -f docker-compose-ag2.yml build --no-cache streamlit-ui
```

### Database Not Found

Generate database:

```bash
cd data && python setup_database.py
```

## Observability

### Phoenix Tracing

Phoenix automatically traces all LLM calls and agent interactions with zero configuration.

**Access Phoenix UI**: http://localhost:6006

**Features**:
- Automatic instrumentation (no decorators needed)
- Real-time trace visualization
- Agent conversation flow
- LLM call details (tokens, latency, costs)
- Tool execution tracking

**No Setup Required**: Traces appear automatically after executing queries in the Streamlit UI.

## Performance

**Benchmarks** (Apple M4 Max, 128GB RAM):

| Query Type | Agent | Time | Tokens |
|------------|-------|------|--------|
| Simple SQL | SQL | 2-5s | ~500 |
| Web Search | Web | 5-10s | ~800 |
| Analysis | Multi | 15-30s | ~2000 |

**Optimization Tips**:

- Reduce `max_round` for simple queries
- Use smaller model (gemma2:2b) for faster responses
- Limit tool result sizes
- Enable LLM response caching



## Project Structure

```text
nl2sql-agent/
â”œâ”€â”€ function/
â”‚   â”œâ”€â”€ ag2_orchestrator.py      # Multi-agent orchestration
â”‚   â”œâ”€â”€ database.py               # DuckDB connection
â”‚   â””â”€â”€ mcp_tools/                # MCP tool implementations
â”‚       â”œâ”€â”€ database.py           # DB schema/query tools
â”‚       â”œâ”€â”€ web.py                # Search/scrape tools
â”‚       â””â”€â”€ interpreter.py        # Safe Python execution
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                    # Streamlit interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ setup_database.py         # Sample data generator
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture.md           # Detailed architecture docs
â””â”€â”€ docker-compose-ag2.yml        # Deployment config
```

## License

MIT License

## References

- [AG2 (AutoGen) Documentation](https://microsoft.github.io/autogen/)
- [DuckDB Documentation](https://duckdb.org/docs/)
- [Phoenix (Arize AI) Documentation](https://docs.arize.com/phoenix)
- [Streamlit Documentation](https://docs.streamlit.io/)
